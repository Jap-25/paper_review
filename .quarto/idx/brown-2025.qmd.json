{"title":"Alpha Earth Foundation","markdown":{"yaml":{"title":"Alpha Earth Foundation","subtitle":"AlphaEarth Foundations: An embedding field model for accurate and efficient global mapping from sparse label data","author":"@brown2025alphaearth"},"headingText":"Informaci√≥n B√°sica","containsRefs":false,"markdown":"\n\n\n| Elemento | Detalle |\n|--------------------------------------|----------------------------------|\n| **Referencia** | @brown2025alphaearth |\n| **T√≠tulo completo** | AlphaEarth Foundations: An embedding field model for accurate and efficient global mapping from sparse label data |\n| **Revista / Volumen / DOI** | <https://doi.org/10.48550/arXiv.2507.22291> |\n| **Tem√°tica** | Modelos fundacionales geoespaciales; aprendizaje autom√°tico con datos de observaci√≥n de la Tierra |\n| **Contexto / Problema** | La enorme cantidad de datos satelitales disponibles supera la capacidad de etiquetado con observaciones de campo, lo que limita la creaci√≥n eficiente de mapas globales precisos. Se requieren m√©todos que puedan generalizar desde pocos datos etiquetados a escala planetaria. |\n|**Keywords** | Earth Observation, Embedding Fields, Sparse Labels, Remote Sensing, Global Mapping, Machine Learning|\n\n## Abstract\n\n**Original:**\n: Unprecedented volumes of Earth observation data are continually collected around the world, but high-quality labels remain scarce given the effort required to make physical measurements and observations. This has led to considerable investment in bespoke modeling efforts translating sparse labels into maps. Here we introduce AlphaEarth Foundations, an embedding field model yielding a highly general, geospatial representation that assimilates spatial, temporal, and measurement contexts across multiple sources, enabling accurate and efficient production of maps and monitoring systems from local to global scales. The embeddings generated by AlphaEarth Foundations are the only to consistently outperform all previous featurization approaches tested on a diverse set of mapping evaluations without re-training. We will release a dataset of global, annual, analysis-ready embedding field layers from 2017 through 2024.\n\n\n**Traducci√≥n al espa√±ol:**\n: Se recolectan vol√∫menes sin precedentes de datos de observaci√≥n de la Tierra en todo el mundo, pero las etiquetas de alta calidad siguen siendo escasas debido al esfuerzo requerido para realizar mediciones f√≠sicas y observaciones. Esto ha motivado una considerable inversi√≥n en modelos personalizados que traducen etiquetas escasas en mapas. Aqu√≠ presentamos AlphaEarth Foundations, un modelo de campos de incrustaci√≥n que produce una representaci√≥n geoespacial altamente general que asimila contextos espaciales, temporales y de medici√≥n desde m√∫ltiples fuentes, permitiendo la producci√≥n precisa y eficiente de mapas y sistemas de monitoreo desde escalas locales a globales. Las incrustaciones generadas por AlphaEarth Foundations son las √∫nicas que superan consistentemente a todos los enfoques anteriores de featurizaci√≥n evaluados en un conjunto diverso de tareas de mapeo, sin necesidad de reentrenamiento. Publicaremos un conjunto de datos global, anual, y listo para an√°lisis de capas de campos de incrustaci√≥n desde 2017 hasta 2024.\n\n## Preguntas de Investigaci√≥n / Hip√≥tesis\n\n> -   ¬øC√≥mo puede un modelo fundacional geoespacial integrar m√∫ltiples fuentes de datos y escasa etiquetaci√≥n para producir mapas precisos a nivel global? *(inferida)*\\\n> -   ¬øPuede una representaci√≥n embebida generalizada superar en desempe√±o a m√©todos especializados en escenarios con datos escasos? *(inferida)*\n\n## Metodolog√≠a\n\n### Flujo de trabajo\n\n1.  Preprocesamiento y normalizaci√≥n de datos EO multifuente.\\\n2.  Codificaci√≥n con arquitectura Space-Time Precision (STP) para generar representaciones latentes.\\\n3.  Entrenamiento de modelos maestros/alumnos y de alineaci√≥n con texto.\\\n4.  Generaci√≥n de ‚Äúcampos de incrustaci√≥n‚Äù anuales con resoluci√≥n espacial de 10m¬≤.\\\n5.  Evaluaci√≥n sobre 15 tareas geogr√°ficas en escenarios de escasez de datos.\n\n### Modelos / Algoritmos\n\n> * Arquitectura STP con operadores espacio, tiempo y precisi√≥n intercalados con rescalado tipo Laplaciano.\\\n> * Embedding implicito con p√©rdidas espec√≠ficas por fuente y distribuci√≥n uniforme en ( S\\^{63} ).\\\n> * Modelos tipo ‚Äúteacher-student‚Äù y alineaci√≥n con texto usando contraste.\n\n<br>\n\n![(A) Diagrama general de la arquitectura de red para an√°lisis de video. Los datos brutos se normalizan y se codifican temporalmente con funciones seno. Los codificadores de origen transforman las entradas al mismo espacio latente antes de ingresar al modelo. Las salidas se resumen mediante c√≥digos temporales condicionales espec√≠ficos por fuente y tarea contrastiva. ùúá representa los vectores de embedding. (B) Las salidas del modelo se interpretan como la direcci√≥n media de una distribuci√≥n von Mises-Fisher. La decodificaci√≥n se realiza muestreando esta distribuci√≥n y concatenando los resultados con metadatos del sensor y un c√≥digo temporal relativo al periodo v√°lido. (C) Para evitar el colapso del embedding y mejorar el rendimiento, se comparan los vectores generados con versiones rotadas por lote, minimizando el valor absoluto del producto punto, condici√≥n necesaria para una distribuci√≥n uniforme en ùëÜ‚Å∂¬≥. (D) El n√∫cleo del modelo incluye rutas simult√°neas a distintas resoluciones, equilibrando eficiencia y precisi√≥n espacial. (E) Aprendizaje contrastivo entre el modelo de video maestro, el modelo estudiante y el codificador de texto.(F) Visualizaci√≥n completa del campo de embeddings anual 2023, abarcando toda la superficie terrestre, incluidas islas menores, entre ¬±82¬∞ de latitud.](images/brown-arquitecture.png)\n\n### Datos\n\nEl modelo AEF se entren√≥ con m√°s de 3 mil millones de observaciones distribuidas en diez fuentes (√≥pticas, radar, LiDAR, ambientales y texto), cubriendo aproximadamente 1.1% de la superficie terrestre global. Los datos de entrada fueron reescalados espacialmente y codificados con marcas de tiempo para producir representaciones temporales continuas y espacialmente precisas. Se generaron campos de incrustaci√≥n anuales de 2017 a 2024 y se dise√±√≥ una suite de evaluaci√≥n con 15 tareas usando datos abiertos, balanceados y con separaci√≥n m√≠nima de 1.28 km entre muestras.\n\n| Tipo                | Fuente                   | Cobertura temporal |\n|---------------------|--------------------------|--------------------|\n| Satelital √≥ptico    | Sentinel-2, Landsat 8/9  | 2017‚Äì2024          |\n| Radar               | Sentinel-1, PALSAR2      | 2017‚Äì2024          |\n| LiDAR               | GEDI                     | Variable           |\n| Ambiental           | ERA5-Land, GLO-30, GRACE | Variable           |\n| Anotaciones / texto | NLCD, Wikipedia          | Variable           |\n\n<br>\n![AEF reconcilia m√∫ltiples registros de observaci√≥n dispersos y muestreados de forma no uniforme en un registro continuo.](images/brown-dataset.png){fig-align=\"center\"}\n\n### Validaci√≥n & Uncertainties\n\nLa validaci√≥n se realiz√≥ mediante 15 evaluaciones tem√°ticas (clasificaci√≥n, regresi√≥n, detecci√≥n de cambio), comparando AEF con m√©todos dise√±ados y modelos fundacionales previos. Se probaron distintos tama√±os de muestra (1, 10, m√°ximo por clase), y m√©todos de transferencia (kNN, regresi√≥n lineal). Se emplearon t√©cnicas de *bootstrapping* y validaci√≥n cruzada para estimar intervalos de confianza.\n\n| M√©trica | Valor | Alcance | Notas |\n|------------------|------------------|------------------|------------------|\n| Reducci√≥n de error (max-trial) | 23.9% | Promedio general | vs mejor baseline |\n| Reducci√≥n de error (10-shot) | 10.4% | Promedio |  |\n| Reducci√≥n de error (1-shot) | 4.18% | Promedio |  |\n| ( R\\^2 ) (emissivity) | 0.72 ¬± 0.00 | Global | Mejor resultado |\n| ( R\\^2 ) (evapotranspiration) | 0.58 ¬± 0.01 | EEUU occidental | √önico m√©todo con ( R\\^2 \\> 0.2 ) |\n\n### Replicabilidad & Recursos\n\n| √çtem                          | S√≠/No | Detalle                          |\n|-------------------------------|-------|----------------------------------|\n| C√≥digo abierto                | No    | N/A                              |\n| Datos disponibles             | S√≠    | Google Earth Engine (2017‚Äì2024)  |\n| Evaluaciones disponibles      | S√≠    | Conjunto de 15 datasets abiertos |\n| Manual de uso / documentaci√≥n | S√≠    | En materiales suplementarios     |\n\n## Resultados Clave\n\n-   AEF supera a todos los m√©todos de featurizaci√≥n evaluados, tanto dise√±ados como aprendidos.\\\n-   Reducci√≥n promedio de error del 23.9% en escenarios realistas de entrenamiento.\\\n-   √önico m√©todo con ( R\\^2 \\> 0.2 ) para estimar evapotranspiraci√≥n.\\\n-   Consistencia en resultados en m√∫ltiples dominios (uso/cobertura del suelo, cultivos, variables biof√≠sicas).\\\n-   Alto desempe√±o incluso con pocas muestras por clase (1‚Äì10).\n\n## Discusi√≥n\n\n-   **Contribuciones:** Primer modelo fundacional EO que integra m√∫ltiples fuentes y soporta tiempo continuo; desempe√±o robusto con escasa etiquetaci√≥n; publica embeddings globales abiertos.\\\n-   **Limitaciones:** Requiere grandes vol√∫menes de datos para tareas geogr√°ficamente espec√≠ficas (ej. clasificaci√≥n de √°rboles en EE.UU.); no se public√≥ el c√≥digo del modelo.\\\n-   **Futuro:** Optimizaci√≥n de inferencia, extensi√≥n multitemporal sub-anual, incorporaci√≥n de nuevas fuentes (texto, radar).\n\n## Aplicabilidad en Chile\n\n| Aspecto | Evaluaci√≥n |\n|------------------------------------|------------------------------------|\n| Disponibilidad de datos satelitales | Alta |\n| Escenarios de baja etiquetaci√≥n | Muy relevante |\n| Monitoreo agr√≠cola, forestal y de humedales | Altamente aplicable |\n| Capacidades institucionales para uso | Moderada ‚Äì requiere soporte t√©cnico |\n| Uso en planificaci√≥n territorial y cambio clim√°tico | Potencial significativo |\n\n<br>\n\n![AEF muestra una mayor coherencia espacial sin comprometer la precisi√≥n espacial.](images/brown-application.png){fig-align=\"center\"}\n\n## Madurez & Evidencia\n\n| Eje | Nivel |\n|------------------------------------|------------------------------------|\n| Nivel TRL (Technology Readiness Level) | 7 ‚Äì Validaci√≥n en entornos reales |\n| Reproducibilidad | Alta (datos abiertos, pruebas detalladas) |\n| Robustez metodol√≥gica | Alta |\n| Generalizaci√≥n geogr√°fica | Muy alta |\n| Dependencia de infraestructura propietaria | Media |\n\n## Impacto en Pol√≠ticas P√∫blicas / ODS\n\n> AlphaEarth Foundations puede habilitar sistemas de monitoreo basados en evidencia para apoyar pol√≠ticas ambientales, agr√≠colas y de gesti√≥n del agua. Su capacidad para generalizar desde pocos datos lo hace especialmente √∫til en regiones con limitada capacidad de recolecci√≥n de datos de campo, como muchas zonas rurales de Chile. Contribuye directamente a los ODS 2 (Hambre cero), 13 (Acci√≥n clim√°tica), y 15 (Vida de ecosistemas terrestres).\n","srcMarkdownNoYaml":"\n\n## Informaci√≥n B√°sica\n\n| Elemento | Detalle |\n|--------------------------------------|----------------------------------|\n| **Referencia** | @brown2025alphaearth |\n| **T√≠tulo completo** | AlphaEarth Foundations: An embedding field model for accurate and efficient global mapping from sparse label data |\n| **Revista / Volumen / DOI** | <https://doi.org/10.48550/arXiv.2507.22291> |\n| **Tem√°tica** | Modelos fundacionales geoespaciales; aprendizaje autom√°tico con datos de observaci√≥n de la Tierra |\n| **Contexto / Problema** | La enorme cantidad de datos satelitales disponibles supera la capacidad de etiquetado con observaciones de campo, lo que limita la creaci√≥n eficiente de mapas globales precisos. Se requieren m√©todos que puedan generalizar desde pocos datos etiquetados a escala planetaria. |\n|**Keywords** | Earth Observation, Embedding Fields, Sparse Labels, Remote Sensing, Global Mapping, Machine Learning|\n\n## Abstract\n\n**Original:**\n: Unprecedented volumes of Earth observation data are continually collected around the world, but high-quality labels remain scarce given the effort required to make physical measurements and observations. This has led to considerable investment in bespoke modeling efforts translating sparse labels into maps. Here we introduce AlphaEarth Foundations, an embedding field model yielding a highly general, geospatial representation that assimilates spatial, temporal, and measurement contexts across multiple sources, enabling accurate and efficient production of maps and monitoring systems from local to global scales. The embeddings generated by AlphaEarth Foundations are the only to consistently outperform all previous featurization approaches tested on a diverse set of mapping evaluations without re-training. We will release a dataset of global, annual, analysis-ready embedding field layers from 2017 through 2024.\n\n\n**Traducci√≥n al espa√±ol:**\n: Se recolectan vol√∫menes sin precedentes de datos de observaci√≥n de la Tierra en todo el mundo, pero las etiquetas de alta calidad siguen siendo escasas debido al esfuerzo requerido para realizar mediciones f√≠sicas y observaciones. Esto ha motivado una considerable inversi√≥n en modelos personalizados que traducen etiquetas escasas en mapas. Aqu√≠ presentamos AlphaEarth Foundations, un modelo de campos de incrustaci√≥n que produce una representaci√≥n geoespacial altamente general que asimila contextos espaciales, temporales y de medici√≥n desde m√∫ltiples fuentes, permitiendo la producci√≥n precisa y eficiente de mapas y sistemas de monitoreo desde escalas locales a globales. Las incrustaciones generadas por AlphaEarth Foundations son las √∫nicas que superan consistentemente a todos los enfoques anteriores de featurizaci√≥n evaluados en un conjunto diverso de tareas de mapeo, sin necesidad de reentrenamiento. Publicaremos un conjunto de datos global, anual, y listo para an√°lisis de capas de campos de incrustaci√≥n desde 2017 hasta 2024.\n\n## Preguntas de Investigaci√≥n / Hip√≥tesis\n\n> -   ¬øC√≥mo puede un modelo fundacional geoespacial integrar m√∫ltiples fuentes de datos y escasa etiquetaci√≥n para producir mapas precisos a nivel global? *(inferida)*\\\n> -   ¬øPuede una representaci√≥n embebida generalizada superar en desempe√±o a m√©todos especializados en escenarios con datos escasos? *(inferida)*\n\n## Metodolog√≠a\n\n### Flujo de trabajo\n\n1.  Preprocesamiento y normalizaci√≥n de datos EO multifuente.\\\n2.  Codificaci√≥n con arquitectura Space-Time Precision (STP) para generar representaciones latentes.\\\n3.  Entrenamiento de modelos maestros/alumnos y de alineaci√≥n con texto.\\\n4.  Generaci√≥n de ‚Äúcampos de incrustaci√≥n‚Äù anuales con resoluci√≥n espacial de 10m¬≤.\\\n5.  Evaluaci√≥n sobre 15 tareas geogr√°ficas en escenarios de escasez de datos.\n\n### Modelos / Algoritmos\n\n> * Arquitectura STP con operadores espacio, tiempo y precisi√≥n intercalados con rescalado tipo Laplaciano.\\\n> * Embedding implicito con p√©rdidas espec√≠ficas por fuente y distribuci√≥n uniforme en ( S\\^{63} ).\\\n> * Modelos tipo ‚Äúteacher-student‚Äù y alineaci√≥n con texto usando contraste.\n\n<br>\n\n![(A) Diagrama general de la arquitectura de red para an√°lisis de video. Los datos brutos se normalizan y se codifican temporalmente con funciones seno. Los codificadores de origen transforman las entradas al mismo espacio latente antes de ingresar al modelo. Las salidas se resumen mediante c√≥digos temporales condicionales espec√≠ficos por fuente y tarea contrastiva. ùúá representa los vectores de embedding. (B) Las salidas del modelo se interpretan como la direcci√≥n media de una distribuci√≥n von Mises-Fisher. La decodificaci√≥n se realiza muestreando esta distribuci√≥n y concatenando los resultados con metadatos del sensor y un c√≥digo temporal relativo al periodo v√°lido. (C) Para evitar el colapso del embedding y mejorar el rendimiento, se comparan los vectores generados con versiones rotadas por lote, minimizando el valor absoluto del producto punto, condici√≥n necesaria para una distribuci√≥n uniforme en ùëÜ‚Å∂¬≥. (D) El n√∫cleo del modelo incluye rutas simult√°neas a distintas resoluciones, equilibrando eficiencia y precisi√≥n espacial. (E) Aprendizaje contrastivo entre el modelo de video maestro, el modelo estudiante y el codificador de texto.(F) Visualizaci√≥n completa del campo de embeddings anual 2023, abarcando toda la superficie terrestre, incluidas islas menores, entre ¬±82¬∞ de latitud.](images/brown-arquitecture.png)\n\n### Datos\n\nEl modelo AEF se entren√≥ con m√°s de 3 mil millones de observaciones distribuidas en diez fuentes (√≥pticas, radar, LiDAR, ambientales y texto), cubriendo aproximadamente 1.1% de la superficie terrestre global. Los datos de entrada fueron reescalados espacialmente y codificados con marcas de tiempo para producir representaciones temporales continuas y espacialmente precisas. Se generaron campos de incrustaci√≥n anuales de 2017 a 2024 y se dise√±√≥ una suite de evaluaci√≥n con 15 tareas usando datos abiertos, balanceados y con separaci√≥n m√≠nima de 1.28 km entre muestras.\n\n| Tipo                | Fuente                   | Cobertura temporal |\n|---------------------|--------------------------|--------------------|\n| Satelital √≥ptico    | Sentinel-2, Landsat 8/9  | 2017‚Äì2024          |\n| Radar               | Sentinel-1, PALSAR2      | 2017‚Äì2024          |\n| LiDAR               | GEDI                     | Variable           |\n| Ambiental           | ERA5-Land, GLO-30, GRACE | Variable           |\n| Anotaciones / texto | NLCD, Wikipedia          | Variable           |\n\n<br>\n![AEF reconcilia m√∫ltiples registros de observaci√≥n dispersos y muestreados de forma no uniforme en un registro continuo.](images/brown-dataset.png){fig-align=\"center\"}\n\n### Validaci√≥n & Uncertainties\n\nLa validaci√≥n se realiz√≥ mediante 15 evaluaciones tem√°ticas (clasificaci√≥n, regresi√≥n, detecci√≥n de cambio), comparando AEF con m√©todos dise√±ados y modelos fundacionales previos. Se probaron distintos tama√±os de muestra (1, 10, m√°ximo por clase), y m√©todos de transferencia (kNN, regresi√≥n lineal). Se emplearon t√©cnicas de *bootstrapping* y validaci√≥n cruzada para estimar intervalos de confianza.\n\n| M√©trica | Valor | Alcance | Notas |\n|------------------|------------------|------------------|------------------|\n| Reducci√≥n de error (max-trial) | 23.9% | Promedio general | vs mejor baseline |\n| Reducci√≥n de error (10-shot) | 10.4% | Promedio |  |\n| Reducci√≥n de error (1-shot) | 4.18% | Promedio |  |\n| ( R\\^2 ) (emissivity) | 0.72 ¬± 0.00 | Global | Mejor resultado |\n| ( R\\^2 ) (evapotranspiration) | 0.58 ¬± 0.01 | EEUU occidental | √önico m√©todo con ( R\\^2 \\> 0.2 ) |\n\n### Replicabilidad & Recursos\n\n| √çtem                          | S√≠/No | Detalle                          |\n|-------------------------------|-------|----------------------------------|\n| C√≥digo abierto                | No    | N/A                              |\n| Datos disponibles             | S√≠    | Google Earth Engine (2017‚Äì2024)  |\n| Evaluaciones disponibles      | S√≠    | Conjunto de 15 datasets abiertos |\n| Manual de uso / documentaci√≥n | S√≠    | En materiales suplementarios     |\n\n## Resultados Clave\n\n-   AEF supera a todos los m√©todos de featurizaci√≥n evaluados, tanto dise√±ados como aprendidos.\\\n-   Reducci√≥n promedio de error del 23.9% en escenarios realistas de entrenamiento.\\\n-   √önico m√©todo con ( R\\^2 \\> 0.2 ) para estimar evapotranspiraci√≥n.\\\n-   Consistencia en resultados en m√∫ltiples dominios (uso/cobertura del suelo, cultivos, variables biof√≠sicas).\\\n-   Alto desempe√±o incluso con pocas muestras por clase (1‚Äì10).\n\n## Discusi√≥n\n\n-   **Contribuciones:** Primer modelo fundacional EO que integra m√∫ltiples fuentes y soporta tiempo continuo; desempe√±o robusto con escasa etiquetaci√≥n; publica embeddings globales abiertos.\\\n-   **Limitaciones:** Requiere grandes vol√∫menes de datos para tareas geogr√°ficamente espec√≠ficas (ej. clasificaci√≥n de √°rboles en EE.UU.); no se public√≥ el c√≥digo del modelo.\\\n-   **Futuro:** Optimizaci√≥n de inferencia, extensi√≥n multitemporal sub-anual, incorporaci√≥n de nuevas fuentes (texto, radar).\n\n## Aplicabilidad en Chile\n\n| Aspecto | Evaluaci√≥n |\n|------------------------------------|------------------------------------|\n| Disponibilidad de datos satelitales | Alta |\n| Escenarios de baja etiquetaci√≥n | Muy relevante |\n| Monitoreo agr√≠cola, forestal y de humedales | Altamente aplicable |\n| Capacidades institucionales para uso | Moderada ‚Äì requiere soporte t√©cnico |\n| Uso en planificaci√≥n territorial y cambio clim√°tico | Potencial significativo |\n\n<br>\n\n![AEF muestra una mayor coherencia espacial sin comprometer la precisi√≥n espacial.](images/brown-application.png){fig-align=\"center\"}\n\n## Madurez & Evidencia\n\n| Eje | Nivel |\n|------------------------------------|------------------------------------|\n| Nivel TRL (Technology Readiness Level) | 7 ‚Äì Validaci√≥n en entornos reales |\n| Reproducibilidad | Alta (datos abiertos, pruebas detalladas) |\n| Robustez metodol√≥gica | Alta |\n| Generalizaci√≥n geogr√°fica | Muy alta |\n| Dependencia de infraestructura propietaria | Media |\n\n## Impacto en Pol√≠ticas P√∫blicas / ODS\n\n> AlphaEarth Foundations puede habilitar sistemas de monitoreo basados en evidencia para apoyar pol√≠ticas ambientales, agr√≠colas y de gesti√≥n del agua. Su capacidad para generalizar desde pocos datos lo hace especialmente √∫til en regiones con limitada capacidad de recolecci√≥n de datos de campo, como muchas zonas rurales de Chile. Contribuye directamente a los ODS 2 (Hambre cero), 13 (Acci√≥n clim√°tica), y 15 (Vida de ecosistemas terrestres).\n"},"formats":{"html":{"identifier":{"display-name":"HTML","target-format":"html","base-format":"html"},"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":false,"echo":true,"output":true,"warning":false,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"ipynb-shell-interactivity":null,"plotly-connected":true,"engine":"markdown"},"render":{"keep-tex":false,"keep-typ":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"center","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-min-runs":1,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[],"notebook-links":true},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","html-math-method":"katex","css":["styles/style.css"],"output-file":"brown-2025.html"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","other-links-title":"Other Links","code-links-title":"Code Links","launch-dev-container-title":"Launch Dev Container","launch-binder-title":"Launch Binder","article-notebook-label":"Article Notebook","notebook-preview-download":"Download Notebook","notebook-preview-download-src":"Download Source","notebook-preview-back":"Back to Article","manuscript-meca-bundle":"MECA Bundle","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","appendix-view-license":"View License","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","title-block-keywords":"Keywords","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","tools-share":"Share","tools-download":"Download","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-text-placeholder":"","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-wordcount":"Word Count","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items","listing-page-words":"{0} words","listing-page-filter":"Filter","draft":"Draft"},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.7.31","bibliography":["references.bib"],"editor":"source","always_allow_html":true,"_quarto-vars":{"version":1,"email":{"author":"<denis.berroeta@uai.cl>"},"author":{"name":"[Denis Berroeta](https://cit.uai.cl/denis-berroeta/)","cargo":"Coordinador de Investigaci√≥n, Centro de Inteligencia Territorial - UAI","email":"<denis.berroeta@uai.cl>"},"engine":{"jupyter":"[Jupyter](https://jupyter.org)","knitr":"[Knitr](<https://yihui.name/knitr>)","R":"[R Project](https://www.r-project.org)","python":"[Python](https://docs.python.org/es/3/tutorial/)"},"software":{"rstudio":"[RStudio](https://posit.co/products/open-source/rstudio/)"},"library":{"sf":"[Simple Features for R](https://r-spatial.github.io/sf/articles/sf1.html)","dplyr":"[dplyr](https://dplyr.tidyverse.org)","purrr":"[purrr](https://purrr.tidyverse.org)","mapview":"[mapview](https://r-spatial.github.io/mapview/)","lubridate":"[lubridate](https://lubridate.tidyverse.org)","tidyr":"[tidyr](https://tidyr.tidyverse.org)","plotly":"[plotly](https://plotly.com/r/)","ggplot":"[ggplot2](https://ggplot2.tidyverse.org/)"},"organization":{"ine":"[Instituto Nacional de Estad√≠sticas](https://www.ine.gob.cl)","cran":"[CRAN (Comprehensive R Archive Network)](https://cran.r-project.org/)","bioconductor":"[Bioconductor](https://www.bioconductor.org/)","github":"[Github](https://github.com/)","rforge":"[R-Forge](https://r-forge.r-project.org/)"}},"theme":"cosmo","fig-cap-location":"margin","tab-cap-location":"left","mailto":"denis.berroeta@uai.cl","toc-title":"Contenidos","title":"Alpha Earth Foundation","subtitle":"AlphaEarth Foundations: An embedding field model for accurate and efficient global mapping from sparse label data","author":"@brown2025alphaearth"},"extensions":{"book":{"multiFile":true}}}},"projectFormats":["html"]}